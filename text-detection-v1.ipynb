{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Loading the packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install imutils","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-19T18:02:58.851634Z","start_time":"2019-08-19T18:02:58.28851Z"},"trusted":true},"cell_type":"code","source":"##Loading the necessary packages \nimport numpy as np\nimport cv2\nfrom imutils.object_detection import non_max_suppression\nimport pytesseract\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating argument dictionary with some default values"},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/text-detection/","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-19T18:02:58.987428Z","start_time":"2019-08-19T18:02:58.984293Z"},"trusted":true},"cell_type":"code","source":"#Creating argument dictionary for the default arguments needed in the code. \nargs = {\"image\":\"../input/text-detection/example-images/Example-images/ex24.jpg\", \"east\":\"../input/text-detection/east_text_detection.pb\", \"min_confidence\":0.5, \"width\":320, \"height\":320}\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Image processing"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-19T18:02:59.966698Z","start_time":"2019-08-19T18:02:59.951848Z"},"trusted":true},"cell_type":"code","source":"#Give location of the image to be read.\n#\"Example-images/ex24.jpg\" image is being loaded here. \n\nargs['image']=\"../input/text-detection/example-images/Example-images/ex24.jpg\"\nimage = cv2.imread(args['image'])\n\n#Saving a original image and shape\norig = image.copy()\n(origH, origW) = image.shape[:2]\n\n# set the new height and width to default 320 by using args #dictionary.  \n(newW, newH) = (args[\"width\"], args[\"height\"])\n\n#Calculate the ratio between original and new image for both height and weight. \n#This ratio will be used to translate bounding box location on the original image. \nrW = origW / float(newW)\nrH = origH / float(newH)\n\n# resize the original image to new dimensions\nimage = cv2.resize(image, (newW, newH))\n(H, W) = image.shape[:2]\n\n# construct a blob from the image to forward pass it to EAST model\nblob = cv2.dnn.blobFromImage(image, 1.0, (W, H),\n\t(123.68, 116.78, 103.94), swapRB=True, crop=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading Pre-trained EAST model and defining output layers"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-19T18:03:01.17032Z","start_time":"2019-08-19T18:03:00.551916Z"},"trusted":true},"cell_type":"code","source":"# load the pre-trained EAST model for text detection \nnet = cv2.dnn.readNet(args[\"east\"])\n\n# We would like to get two outputs from the EAST model. \n#1. Probabilty scores for the region whether that contains text or not. \n#2. Geometry of the text -- Coordinates of the bounding box detecting a text\n# The following two layer need to pulled from EAST model for achieving this. \nlayerNames = [\n\t\"feature_fusion/Conv_7/Sigmoid\",\n\t\"feature_fusion/concat_3\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Forward pass the image through EAST model"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-19T18:03:01.390723Z","start_time":"2019-08-19T18:03:01.172468Z"},"trusted":true},"cell_type":"code","source":"#Forward pass the blob from the image to get the desired output layers\nnet.setInput(blob)\n(scores, geometry) = net.forward(layerNames)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Function to decode bounding box from EAST model prediction "},{"metadata":{"ExecuteTime":{"end_time":"2019-08-19T18:03:01.794226Z","start_time":"2019-08-19T18:03:01.783623Z"},"trusted":true},"cell_type":"code","source":"## Returns a bounding box and probability score if it is more than minimum confidence\ndef predictions(prob_score, geo):\n\t(numR, numC) = prob_score.shape[2:4]\n\tboxes = []\n\tconfidence_val = []\n\n\t# loop over rows\n\tfor y in range(0, numR):\n\t\tscoresData = prob_score[0, 0, y]\n\t\tx0 = geo[0, 0, y]\n\t\tx1 = geo[0, 1, y]\n\t\tx2 = geo[0, 2, y]\n\t\tx3 = geo[0, 3, y]\n\t\tanglesData = geo[0, 4, y]\n\n\t\t# loop over the number of columns\n\t\tfor i in range(0, numC):\n\t\t\tif scoresData[i] < args[\"min_confidence\"]:\n\t\t\t\tcontinue\n\n\t\t\t(offX, offY) = (i * 4.0, y * 4.0)\n\n\t\t\t# extracting the rotation angle for the prediction and computing the sine and cosine\n\t\t\tangle = anglesData[i]\n\t\t\tcos = np.cos(angle)\n\t\t\tsin = np.sin(angle)\n\n\t\t\t# using the geo volume to get the dimensions of the bounding box\n\t\t\th = x0[i] + x2[i]\n\t\t\tw = x1[i] + x3[i]\n\n\t\t\t# compute start and end for the text pred bbox\n\t\t\tendX = int(offX + (cos * x1[i]) + (sin * x2[i]))\n\t\t\tendY = int(offY - (sin * x1[i]) + (cos * x2[i]))\n\t\t\tstartX = int(endX - w)\n\t\t\tstartY = int(endY - h)\n\n\t\t\tboxes.append((startX, startY, endX, endY))\n\t\t\tconfidence_val.append(scoresData[i])\n\n\t# return bounding boxes and associated confidence_val\n\treturn (boxes, confidence_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this exercise, we are only decoding horizontal bounding boxes. Decoding rotating bounding boxes from the scores and geometry is more complex. "},{"metadata":{},"cell_type":"markdown","source":"## Getting final bounding boxes after non max suppression"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-19T18:03:03.896118Z","start_time":"2019-08-19T18:03:03.874065Z"},"trusted":true},"cell_type":"code","source":"# Find predictions and  apply non-maxima suppression\n(boxes, confidence_val) = predictions(scores, geometry)\nboxes = non_max_suppression(np.array(boxes), probs=confidence_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Generating list with bounding box coordinates and recognized text in the boxes"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-19T18:03:05.653409Z","start_time":"2019-08-19T18:03:05.231452Z"},"trusted":true},"cell_type":"code","source":"##Text Detection and Recognition \n\n# initialize the list of results\nresults = []\n\n# loop over the bounding boxes to find the coordinate of bounding boxes\nfor (startX, startY, endX, endY) in boxes:\n\t# scale the coordinates based on the respective ratios in order to reflect bounding box on the original image\n\tstartX = int(startX * rW)\n\tstartY = int(startY * rH)\n\tendX = int(endX * rW)\n\tendY = int(endY * rH)\n\n\t#extract the region of interest\n\tr = orig[startY:endY, startX:endX]\n\n\t#configuration setting to convert image to string.  \n\tconfiguration = (\"-l eng --oem 1 --psm 8\")\n    ##This will recognize the text from the image of bounding box\n\ttext = pytesseract.image_to_string(r, config=configuration)\n\n\t# append bbox coordinate and associated text to the list of results \n\tresults.append(((startX, startY, endX, endY), text))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Display image with bounding box and recognized text"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Display the image with bounding box and recognized text\norig_image = orig.copy()\n\n# Moving over the results and display on the image\nfor ((start_X, start_Y, end_X, end_Y), text) in results:\n\t# display the text detected by Tesseract\n\tprint(\"{}\\n\".format(text))\n\n\t# Displaying text\n\ttext = \"\".join([x if ord(x) < 128 else \"\" for x in text]).strip()\n\tcv2.rectangle(orig_image, (start_X, start_Y), (end_X, end_Y),\n\t\t(0, 0, 255), 2)\n\tcv2.putText(orig_image, text, (start_X, start_Y - 30),\n\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,0, 255), 2)\n\nplt.imshow(orig_image)\nplt.title('Output')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":4}